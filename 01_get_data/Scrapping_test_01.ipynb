{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('/Users/adriaferrer/IDIADA_Repos/Moneyball/01_get_data/chromedriver')\n",
    "\n",
    "username = 'minandaandcastolo@gmail.com'\n",
    "password = 'wholetthedogs0ut'\n",
    "\n",
    "# Open the site and click to go to login\n",
    "driver.get('https://biwenger.as.com/login')\n",
    "driver.find_element_by_css_selector('button').click()\n",
    "\n",
    "# Login\n",
    "driver.find_element_by_css_selector('input').send_keys(username + Keys.TAB + password + Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "\n",
    "        # Extract current hash tag name\n",
    "        tag_name = tag\n",
    "\n",
    "        # Extract all post links from 'explore tags' page\n",
    "        post_links = []\n",
    "\n",
    "        if scroll == 0:\n",
    "            soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            recent = soup.find_all('div', {'class': 'Nnq7C weEfm'})\n",
    "            recent = recent[4:]\n",
    "            for row in recent:\n",
    "                for a in row.find_all('a', href=True):\n",
    "                    post_links.append(a['href'])\n",
    "        else:\n",
    "            for times in range(scroll):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(1)\n",
    "            recent = driver.find_elements_by_class_name('KC1QD')\n",
    "            for row in recent:\n",
    "                recent = row.find_elements_by_tag_name('a')\n",
    "            for a in recent:\n",
    "                post_links.append(a.get_attribute('href').strip('https://www.instagram.com'))\n",
    "            post_links = post_links[9:]\n",
    "\n",
    "        # Keep link of only 30 most recent posts\n",
    "        if scroll == 0:\n",
    "            clean_post_links = [x for x in post_links if x.startswith('/p/')]\n",
    "        else:\n",
    "            clean_post_links = ['/p/' + x for x in post_links]\n",
    "\n",
    "        del clean_post_links[30:]\n",
    "\n",
    "        # Extract the info for each post of the tag\n",
    "        for post_id in range(len(clean_post_links)):\n",
    "\n",
    "            # Add tag name\n",
    "            tag_name_list.append(tag)\n",
    "            driver.get('https://www.instagram.com' + str(clean_post_links[post_id]))\n",
    "            soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "\n",
    "            # Add post id\n",
    "            post_ids_list.append(str(clean_post_links[post_id]))\n",
    "\n",
    "            # Add likes, if any\n",
    "            likes = soup.find('div', {'class': 'Nm9Fw'})\n",
    "            if likes is None:\n",
    "                likes_list.append('0')\n",
    "            else:\n",
    "                try:\n",
    "                    likes_list.append(likes.find('span').text)\n",
    "                except:\n",
    "                    likes_list.append('1')\n",
    "\n",
    "            # Add timestamp\n",
    "            i = soup.find('time')\n",
    "            if i is None:\n",
    "                post_time_list.append(np.nan)\n",
    "            else:\n",
    "                post_time_list.append(i['datetime'])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Add hash tag info to data frame\n",
    "\n",
    "tag_df = pd.DataFrame({'tags': tag_name_list, 'postid': post_ids_list, 'date': post_time_list, 'likes': likes_list})\n",
    "\n",
    "# Data cleaning: removal of duplicates and incomplete data\n",
    "tag_df['postid'] = tag_df['postid'].str.strip('/p/')\n",
    "tag_df['date'] = tag_df['date'].astype('datetime64')\n",
    "tag_df['likes'] = tag_df['likes'].astype('float64')\n",
    "unique_tags_df = tag_df.drop_duplicates(subset='postid')\n",
    "unique_tags_df_nona = unique_tags_df.dropna()\n",
    "\n",
    "# upload to DB\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'root'\n",
    "password = ''#password goes here\n",
    "ip = '35.195.111.11'\n",
    "database = 'Avocalypse'\n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "unique_tags_df_nona.to_sql('insta_posts_notnull', con=engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
